#!/usr/bin/env python3
import csv
import io
import json
import os
import subprocess
import sys
import shutil
import textwrap
from urllib.request import urlopen
from urllib.error import URLError
from optparse import OptionParser, IndentedHelpFormatter


SQL_URL = "https://raw.githubusercontent.com/earendil-works/absurd/refs/heads/main/sql/absurd.sql"


def get_term_width():
    """Get terminal width for formatting."""
    try:
        return shutil.get_terminal_size().columns
    except Exception:
        return 80


class CleanHelpFormatter(IndentedHelpFormatter):
    """Custom formatter with better spacing and formatting."""

    def __init__(self):
        IndentedHelpFormatter.__init__(
            self,
            indent_increment=2,
            max_help_position=30,
            width=get_term_width(),
            short_first=1,
        )

    def format_option(self, option):
        result = []
        opts = self.option_strings[option]
        opt_width = self.help_position - self.current_indent - 2

        if len(opts) > opt_width:
            opts = "%*s%s\n" % (self.current_indent, "", opts)
            indent_first = self.help_position
        else:
            opts = "%*s%-*s  " % (self.current_indent, "", opt_width, opts)
            indent_first = 0

        result.append(opts)

        if option.help:
            help_text = self.expand_default(option)
            help_lines = []

            help_lines = textwrap.wrap(help_text, self.width - self.help_position)

            result.append("%*s%s\n" % (indent_first, "", help_lines[0]))
            for line in help_lines[1:]:
                result.append("%*s%s\n" % (self.help_position, "", line))
        elif opts[-1] != "\n":
            result.append("\n")

        return "".join(result)


def build_database_config(host=None, port=None, user=None, database=None):
    """Build a dict with database configuration."""
    return {
        "host": host or os.getenv("PGHOST", "localhost"),
        "port": port or os.getenv("PGPORT", "5432"),
        "user": user or os.getenv("PGUSER", os.getenv("USER", "")),
        "database": database or os.getenv("PGDATABASE", os.getenv("USER", "")),
    }


def config_from_options(options):
    """Shortcut to construct a database config from parsed options."""
    return build_database_config(
        options.host,
        options.port,
        options.user,
        options.database,
    )


def build_psql_command(config, extra_args=None):
    """Construct the base psql command with optional additional arguments."""
    cmd = [
        "psql",
        "-X",
        "-h",
        config["host"],
        "-p",
        config["port"],
        "-U",
        config["user"],
        "-d",
        config["database"],
    ]

    if extra_args:
        cmd.extend(extra_args)

    return cmd


def get_common_db_details(config):
    """Return standard database connection details for verbose output."""
    return [
        ("Host", config["host"]),
        ("Port", config["port"]),
        ("User", config["user"]),
        ("Database", config["database"]),
    ]


def print_verbose_configuration(enabled, details):
    """Print a formatted configuration block when verbose output is enabled."""
    if not enabled:
        return
    print("Configuration:")
    for label, value in details:
        print(f"  {label}: {value}")


def run_psql(
    config,
    query=None,
    *,
    tuples_only=False,
    no_align=False,
    extra_args=None,
    input_data=None,
    error_message=None,
    strip_output=True,
):
    """
    Execute a PostgreSQL command. Returns stripped stdout for queries and the
    CompletedProcess for other invocations.
    """
    cmd_args = []

    if tuples_only:
        cmd_args.append("-t")
    if no_align:
        cmd_args.append("-A")
    if extra_args:
        cmd_args.extend(extra_args)
    if query is not None:
        cmd_args.extend(["-c", query])

    message = error_message
    if message is None:
        message = (
            "Error executing query"
            if query is not None
            else "Error executing psql command"
        )

    env = os.environ.copy()
    env["PGPASSWORD"] = os.getenv("PGPASSWORD", "")
    try:
        result = subprocess.run(
            build_psql_command(config, cmd_args),
            input=input_data,
            capture_output=True,
            text=True,
            check=True,
            env=env,
        )
    except subprocess.CalledProcessError as e:
        print(f"{message}: {e.stderr}", file=sys.stderr)
        sys.exit(1)

    if query is not None:
        return result.stdout.strip() if strip_output else result.stdout
    return result


def run_psql_csv(config, query):
    """Execute a query and return rows parsed via CSV output."""
    output = run_psql(
        config,
        query,
        tuples_only=True,
        extra_args=["--csv"],
        strip_output=False,
    )
    if not output:
        return []

    reader = csv.reader(io.StringIO(output))
    return [row for row in reader if row]


def queue_exists(config, queue_name):
    """Check if a queue exists."""
    result = run_psql(
        config,
        f"SELECT COUNT(*) FROM absurd.queues WHERE queue_name = '{queue_name}';",
        tuples_only=True,
        no_align=True,
    )
    return int(result) > 0


def build_json_params(param_list, base_params=None):
    """
    Build JSON parameters from -p flags and optional base --params.

    Supports:
      -p foo=bar           -> {"foo": "bar"}
      -p count:=42         -> {"count": 42}
      -p enabled:=true     -> {"enabled": true}
      -p tags:='["a","b"]' -> {"tags": ["a","b"]}
      -p user.name=Alice   -> {"user": {"name": "Alice"}}
      --params '{"x":1}'   -> merged with -p flags
    """
    result = {}

    if base_params:
        try:
            result = json.loads(base_params)
            if not isinstance(result, dict):
                raise ValueError("--params must be a JSON object")
        except json.JSONDecodeError as e:
            print(f"Error parsing --params: {e}", file=sys.stderr)
            sys.exit(1)

    for param in param_list:
        if ":=" in param:
            key, value_str = param.split(":=", 1)
            try:
                value = json.loads(value_str)
            except json.JSONDecodeError as e:
                print(f"Error parsing JSON value in '{param}': {e}", file=sys.stderr)
                sys.exit(1)
        elif "=" in param:
            key, value = param.split("=", 1)
        else:
            print(
                f"Invalid parameter format: '{param}' (expected key=value or key:=json)",
                file=sys.stderr,
            )
            sys.exit(1)

        set_nested_value(result, key, value)

    return json.dumps(result)


def set_nested_value(obj, path, value):
    """Set a value in a nested dictionary using dot notation."""
    keys = path.split(".")
    current = obj

    for key in keys[:-1]:
        if key not in current:
            current[key] = {}
        elif not isinstance(current[key], dict):
            print(
                f"Error: Cannot set nested value, '{key}' is not an object",
                file=sys.stderr,
            )
            sys.exit(1)
        current = current[key]

    current[keys[-1]] = value


def add_db_options(parser):
    """Add common database connection options to a parser."""
    parser.add_option("-h", "--host", dest="host", metavar="HOST", help="Database host")
    parser.add_option("-p", "--port", dest="port", metavar="PORT", help="Database port")
    parser.add_option("-U", "--user", dest="user", metavar="USER", help="Database user")
    parser.add_option(
        "-d", "--database", dest="database", metavar="DB", help="Database name"
    )
    parser.add_option(
        "-v",
        "--verbose",
        dest="verbose",
        action="store_true",
        default=False,
        help="Verbose output",
    )


def build_command_parser(usage):
    """Create an OptionParser with common Absurd defaults."""
    parser = OptionParser(
        usage=usage,
        add_help_option=False,
        formatter=CleanHelpFormatter(),
    )
    add_db_options(parser)
    parser.add_option("--help", action="store_true", help="Show this help message")
    return parser


def parse_args_with_help(parser, args, examples=None):
    """Parse args and handle --help in a consistent way."""
    options, remaining = parser.parse_args(args)
    if getattr(options, "help", False):
        parser.print_help()
        if examples:
            print("\nExamples:")
            for example in examples:
                print(f"  {example}")
        sys.exit(0)
    return options, remaining


def ensure_queue_exists(config, queue_name):
    """Exit with error if queue is missing."""
    if not queue_exists(config, queue_name):
        print(f"Queue '{queue_name}' does not exist", file=sys.stderr)
        sys.exit(1)


def cmd_cleanup(args):
    """Clean up old completed, failed, or cancelled tasks and events."""
    usage = "usage: %prog cleanup [options] QUEUE_NAME TTL_DAYS"
    parser = build_command_parser(usage)
    parser.add_option(
        "-l",
        "--limit",
        dest="limit",
        type="int",
        default=1000,
        help="Batch size for deletions (default: 1000)",
    )
    parser.add_option(
        "-n",
        "--dry-run",
        dest="dry_run",
        action="store_true",
        default=False,
        help="Show what would be deleted without actually deleting",
    )
    examples = [
        "absurdctl cleanup myqueue 30",
        "absurdctl cleanup --dry-run -v myqueue 30",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    if len(args) != 2:
        print(
            "Error: Missing required arguments QUEUE_NAME and TTL_DAYS", file=sys.stderr
        )
        parser.print_help()
        sys.exit(1)

    queue_name = args[0]
    try:
        ttl_days = int(args[1])
    except ValueError:
        print(
            f"Error: TTL_DAYS must be a positive integer, got: {args[1]}",
            file=sys.stderr,
        )
        sys.exit(1)

    config = config_from_options(options)
    ensure_queue_exists(config, queue_name)

    ttl_seconds = ttl_days * 24 * 60 * 60

    print_verbose_configuration(
        options.verbose,
        [
            ("Queue", queue_name),
            ("TTL", f"{ttl_days} days ({ttl_seconds} seconds)"),
        ]
        + get_common_db_details(config)
        + [
            ("Limit", options.limit),
            ("Dry run", options.dry_run),
        ],
    )

    if options.dry_run:
        print("DRY RUN MODE - No data will be deleted")

        task_count = run_psql(
            config,
            f"""SELECT COUNT(*) FROM absurd.t_{queue_name} t
                LEFT JOIN absurd.r_{queue_name} r ON r.run_id = t.last_attempt_run
                WHERE t.state IN ('completed', 'failed', 'cancelled')
                AND ((t.state = 'completed' AND r.completed_at < NOW() - INTERVAL '{ttl_seconds} seconds')
                OR (t.state = 'failed' AND r.failed_at < NOW() - INTERVAL '{ttl_seconds} seconds')
                OR (t.state = 'cancelled' AND t.cancelled_at < NOW() - INTERVAL '{ttl_seconds} seconds'));""",
            tuples_only=True,
            no_align=True,
        )

        event_count = run_psql(
            config,
            f"SELECT COUNT(*) FROM absurd.e_{queue_name} WHERE emitted_at < NOW() - INTERVAL '{ttl_seconds} seconds';",
            tuples_only=True,
            no_align=True,
        )

        print(f"Would delete {task_count} tasks and {event_count} events")
        return

    print(f"Starting cleanup for queue '{queue_name}' (TTL: {ttl_days} days)")

    total_tasks_deleted = 0
    total_events_deleted = 0
    iteration = 0

    while True:
        iteration += 1

        if options.verbose:
            print(f"Iteration {iteration}...")

        tasks_deleted = int(
            run_psql(
                config,
                f"SELECT absurd.cleanup_tasks('{queue_name}', {ttl_seconds}, {options.limit});",
                tuples_only=True,
                no_align=True,
            )
        )
        total_tasks_deleted += tasks_deleted

        if options.verbose and tasks_deleted > 0:
            print(f"  Deleted {tasks_deleted} tasks")

        events_deleted = int(
            run_psql(
                config,
                f"SELECT absurd.cleanup_events('{queue_name}', {ttl_seconds}, {options.limit});",
                tuples_only=True,
                no_align=True,
            )
        )
        total_events_deleted += events_deleted

        if options.verbose and events_deleted > 0:
            print(f"  Deleted {events_deleted} events")

        if tasks_deleted == 0 and events_deleted == 0:
            break

        if tasks_deleted > 0 or events_deleted > 0:
            print(f"Deleted {tasks_deleted} tasks, {events_deleted} events")

    print(
        f"Cleanup complete: {total_tasks_deleted} tasks, {total_events_deleted} events deleted in {iteration} iterations"
    )


def cmd_create_queue(args):
    """Create a new Absurd queue."""
    usage = "usage: %prog create-queue [options] QUEUE_NAME"
    parser = build_command_parser(usage)

    options, args = parse_args_with_help(
        parser, args, ["absurdctl create-queue myqueue"]
    )

    if len(args) != 1:
        print("Error: Missing required argument QUEUE_NAME", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    queue_name = args[0]
    config = config_from_options(options)

    print_verbose_configuration(
        options.verbose,
        [("Queue", queue_name)] + get_common_db_details(config),
    )
    if options.verbose:
        print(f"Creating queue '{queue_name}'...")

    run_psql(config, f"SELECT absurd.create_queue('{queue_name}');")
    print(f"Queue '{queue_name}' created successfully")


def cmd_drop_queue(args):
    """Drop an existing Absurd queue."""
    usage = "usage: %prog drop-queue [options] QUEUE_NAME"
    parser = build_command_parser(usage)
    parser.add_option(
        "-y",
        "--yes",
        dest="yes",
        action="store_true",
        default=False,
        help="Skip confirmation prompt",
    )
    examples = [
        "absurdctl drop-queue myqueue",
        "absurdctl drop-queue --yes myqueue",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    if len(args) != 1:
        print("Error: Missing required argument QUEUE_NAME", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    queue_name = args[0]
    config = config_from_options(options)

    ensure_queue_exists(config, queue_name)

    print_verbose_configuration(
        options.verbose,
        [("Queue", queue_name)] + get_common_db_details(config),
    )

    if not options.yes:
        print(
            f"WARNING: This will permanently delete queue '{queue_name}' and all its data."
        )
        response = input("Are you sure you want to continue? (yes/no): ")
        if response != "yes":
            print("Operation cancelled")
            return

    if options.verbose:
        print(f"Dropping queue '{queue_name}'...")

    run_psql(config, f"SELECT absurd.drop_queue('{queue_name}');")
    print(f"Queue '{queue_name}' dropped successfully")


def cmd_list_queues(args):
    """List all existing Absurd queues."""
    usage = "usage: %prog list-queues [options]"
    parser = build_command_parser(usage)

    options, args = parse_args_with_help(parser, args)

    config = config_from_options(options)

    result = run_psql(
        config, "SELECT * FROM absurd.list_queues();", tuples_only=True, no_align=True
    ).strip()
    if result:
        print(result)


def cmd_init(args):
    """Initialize the Absurd schema by applying absurd.sql."""
    usage = "usage: %prog init [options]"
    parser = build_command_parser(usage)

    options, args = parse_args_with_help(parser, args, ["absurdctl init"])

    config = config_from_options(options)

    print_verbose_configuration(options.verbose, get_common_db_details(config))

    script_dir = os.path.dirname(os.path.abspath(__file__))
    local_sql_path = os.path.join(script_dir, "sql", "absurd.sql")

    if os.path.exists(local_sql_path):
        if options.verbose:
            print(f"Using local SQL file: {local_sql_path}")

        result = run_psql(
            config,
            extra_args=["-f", local_sql_path],
            error_message="Error applying SQL file",
        )
    else:
        if options.verbose:
            print(f"Local SQL file not found, fetching from: {SQL_URL}")
        try:
            with urlopen(SQL_URL) as response:
                sql_content = response.read().decode("utf-8")
        except URLError as e:
            print(f"Error downloading SQL file from GitHub: {e}", file=sys.stderr)
            sys.exit(1)
        result = run_psql(
            config, input_data=sql_content, error_message="Error applying SQL file"
        )

    if options.verbose and result.stdout:
        print(result.stdout)
    print("Absurd schema initialized successfully")


def cmd_spawn_task(args):
    """Spawn a new task."""
    usage = "usage: %prog spawn-task [options] TASK_NAME"
    parser = build_command_parser(usage)

    parser.add_option(
        "-q",
        "--queue",
        dest="queue",
        metavar="NAME",
        help="Queue name (default: default)",
    )

    parser.add_option(
        "-P",
        "--param",
        dest="params",
        action="append",
        default=[],
        metavar="K=V",
        help="Task parameter. Use -P key=value for strings or -P key:=json for JSON values. "
        "Supports dotted paths for nested objects (e.g., -P user.name=Alice)",
    )
    parser.add_option(
        "--params",
        dest="base_params",
        metavar="JSON",
        help="Base JSON object for parameters (will be merged with -P flags)",
    )
    parser.add_option(
        "-H",
        "--header",
        dest="headers",
        action="append",
        default=[],
        metavar="K=V",
        help="Task header as key=value pair",
    )

    parser.add_option(
        "--max-attempts",
        dest="max_attempts",
        type="int",
        metavar="N",
        help="Maximum number of retry attempts",
    )
    parser.add_option(
        "--retry-kind",
        dest="retry_kind",
        metavar="KIND",
        help="Retry strategy: fixed, exponential, or none",
    )
    parser.add_option(
        "--retry-base",
        dest="retry_base",
        type="int",
        metavar="SECS",
        help="Base retry delay in seconds",
    )
    parser.add_option(
        "--retry-factor",
        dest="retry_factor",
        type="float",
        metavar="FACTOR",
        help="Exponential backoff multiplier (for exponential retry)",
    )
    parser.add_option(
        "--retry-max",
        dest="retry_max",
        type="int",
        metavar="SECS",
        help="Maximum retry delay cap in seconds",
    )

    parser.add_option(
        "--max-duration",
        dest="max_duration",
        type="int",
        metavar="SECS",
        help="Maximum task execution duration in seconds",
    )
    parser.add_option(
        "--max-delay",
        dest="max_delay",
        type="int",
        metavar="SECS",
        help="Maximum delay before task must start in seconds",
    )

    examples = [
        "absurdctl spawn-task my-task -P foo=bar -P count:=42",
        "absurdctl spawn-task my-task -P user.name=Alice -P user.age:=30",
        'absurdctl spawn-task my-task --params \'{"foo":"bar"}\' -P extra=value',
        "absurdctl spawn-task my-task -P email=test@example.com -q myqueue --max-attempts 5",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    if len(args) != 1:
        print("Error: Missing required argument TASK_NAME", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    task_name = args[0]
    config = config_from_options(options)

    params_json = build_json_params(options.params, options.base_params)

    headers_json = "NULL"
    if options.headers:
        headers_dict = {}
        for header in options.headers:
            if "=" not in header:
                print(
                    f"Invalid header format: '{header}' (expected key=value)",
                    file=sys.stderr,
                )
                sys.exit(1)
            key, value = header.split("=", 1)
            headers_dict[key] = value
        headers_json = f"'{json.dumps(headers_dict)}'::jsonb"

    retry_json = "NULL"
    if (
        options.retry_kind
        or options.retry_base
        or options.retry_factor
        or options.retry_max
    ):
        retry = {"kind": options.retry_kind or "exponential"}
        if options.retry_base:
            retry["baseSeconds"] = options.retry_base
        if options.retry_factor:
            retry["factor"] = options.retry_factor
        if options.retry_max:
            retry["maxSeconds"] = options.retry_max
        retry_json = f"'{json.dumps(retry)}'::jsonb"

    cancellation_json = "NULL"
    if options.max_duration or options.max_delay:
        cancellation = {}
        if options.max_duration:
            cancellation["maxDuration"] = options.max_duration
        if options.max_delay:
            cancellation["maxDelay"] = options.max_delay
        cancellation_json = f"'{json.dumps(cancellation)}'::jsonb"

    queue = options.queue or "default"

    ensure_queue_exists(config, queue)

    details = [
        ("Task", task_name),
        ("Queue", queue),
        ("Params", params_json),
    ]
    if headers_json != "NULL":
        details.append(("Headers", headers_json))
    if options.max_attempts:
        details.append(("Max attempts", options.max_attempts))
    if retry_json != "NULL":
        details.append(("Retry strategy", retry_json))
    if cancellation_json != "NULL":
        details.append(("Cancellation", cancellation_json))
    details.extend(get_common_db_details(config))
    print_verbose_configuration(options.verbose, details)

    query = f"""
        SELECT task_id, run_id, attempt
        FROM absurd.spawn_task(
            '{queue}',
            '{task_name}',
            '{params_json}'::jsonb,
            {headers_json},
            {options.max_attempts or "NULL"},
            {retry_json},
            {cancellation_json}
        );
    """

    rows = run_psql_csv(config, query)

    if rows:
        task_id, run_id, attempt = rows[0]
        print(f"Task spawned successfully:")
        print(f"  Task ID: {task_id}")
        print(f"  Run ID: {run_id}")
        print(f"  Attempt: {attempt}")
    else:
        print("Task spawned, but no result returned", file=sys.stderr)


def format_error_like(data):
    """Try to extract and format error-like objects with name, message, and stack."""
    if not isinstance(data, dict):
        return None

    if "name" in data and "message" in data and "stack" in data:
        return {
            "name": data["name"],
            "message": data["message"],
            "stack": data["stack"],
        }
    return None


def format_json_value(value, indent=0):
    """Format a JSON value with proper indentation."""
    if value is None:
        return "null"

    # Check if it's an error-like object
    error_info = format_error_like(value)
    if error_info:
        lines = []
        lines.append(f"{error_info['name']}")
        lines.append(f"\nMessage:")
        lines.append(f"  {error_info['message']}")
        if error_info["stack"]:
            lines.append(f"\nStack trace:")
            for line in error_info["stack"].split("\n"):
                lines.append(f"  {line}")
        return "\n".join(lines)

    # Otherwise, render as JSON
    return json.dumps(value, indent=2)


def format_timestamp(ts_str):
    """Format a timestamp string in a human-readable way."""
    if not ts_str:
        return "—"
    try:
        from datetime import datetime

        dt = datetime.fromisoformat(ts_str.replace("Z", "+00:00"))
        return dt.strftime("%b %d, %Y %I:%M:%S %p")
    except:
        return ts_str


def format_age(timestamp_str):
    """Format a timestamp as a relative age (e.g., '2h ago', '3d ago')."""
    if not timestamp_str:
        return "—"
    try:
        from datetime import datetime, timezone

        dt = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
        now = datetime.now(timezone.utc)
        delta = now - dt

        seconds = delta.total_seconds()
        if seconds < 60:
            return f"{int(seconds)}s ago"
        elif seconds < 3600:
            return f"{int(seconds / 60)}m ago"
        elif seconds < 86400:
            return f"{int(seconds / 3600)}h ago"
        elif seconds < 604800:
            return f"{int(seconds / 86400)}d ago"
        else:
            return f"{int(seconds / 604800)}w ago"
    except:
        return timestamp_str


def cmd_list_tasks(args):
    """List tasks across queues with filtering options."""
    usage = "usage: %prog list-tasks [options]"
    parser = build_command_parser(usage)
    parser.add_option(
        "-q",
        "--queue",
        dest="queue",
        metavar="NAME",
        help="Filter by queue name",
    )
    parser.add_option(
        "-n",
        "--task-name",
        dest="task_name",
        metavar="NAME",
        help="Filter by task name (exact match)",
    )
    parser.add_option(
        "-s",
        "--status",
        dest="status",
        metavar="STATUS",
        help="Filter by status (pending, running, sleeping, completed, failed, cancelled)",
    )
    parser.add_option(
        "-l",
        "--limit",
        dest="limit",
        type="int",
        default=50,
        metavar="N",
        help="Maximum number of tasks to display (default: 50)",
    )

    examples = [
        "absurdctl list-tasks",
        "absurdctl list-tasks --queue=default",
        "absurdctl list-tasks --status=failed",
        "absurdctl list-tasks --task-name=my-task --queue=default",
        "absurdctl list-tasks --limit=100",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    config = config_from_options(options)

    # Validate status if provided
    valid_statuses = [
        "pending",
        "running",
        "sleeping",
        "completed",
        "failed",
        "cancelled",
    ]
    if options.status and options.status not in valid_statuses:
        print(
            f"Error: Invalid status '{options.status}'. Must be one of: {', '.join(valid_statuses)}",
            file=sys.stderr,
        )
        sys.exit(1)

    # Get list of queues
    queues_result = run_psql(
        config,
        "SELECT queue_name FROM absurd.queues;",
        tuples_only=True,
        no_align=True,
    )

    if not queues_result:
        print("No queues found in the database", file=sys.stderr)
        sys.exit(0)

    queues = [q for q in queues_result.strip().split("\n") if q]

    # Filter to specific queue if requested
    if options.queue:
        if options.queue not in queues:
            print(f"Queue '{options.queue}' does not exist", file=sys.stderr)
            sys.exit(1)
        queues = [options.queue]

    # Build query for each queue and collect results
    all_tasks = []

    for queue in queues:
        # Build WHERE clause based on filters
        where_clauses = []
        if options.task_name:
            where_clauses.append(f"t.task_name = '{options.task_name}'")
        if options.status:
            where_clauses.append(f"t.state = '{options.status}'")

        where_clause = ""
        if where_clauses:
            where_clause = "WHERE " + " AND ".join(where_clauses)

        query = f"""
            SELECT
                t.task_id,
                r.run_id,
                t.task_name,
                '{queue}' as queue_name,
                t.state,
                r.attempt,
                t.max_attempts,
                COALESCE(r.completed_at, r.failed_at, r.started_at, r.created_at) AS updated_at
            FROM absurd.t_{queue} t
            LEFT JOIN absurd.r_{queue} r ON r.run_id = t.last_attempt_run
            {where_clause}
            ORDER BY updated_at DESC
            LIMIT {options.limit}
        """

        rows = run_psql_csv(config, query)

        for parts in rows:
            if len(parts) >= 8:
                all_tasks.append(
                    {
                        "task_id": parts[0],
                        "run_id": parts[1] if parts[1] else "—",
                        "task_name": parts[2],
                        "queue": parts[3],
                        "status": parts[4],
                        "attempt": parts[5],
                        "max_attempts": parts[6] if parts[6] else "∞",
                        "updated_at": parts[7],
                    }
                )

    # Sort all tasks by updated_at descending
    all_tasks.sort(key=lambda x: x["updated_at"], reverse=True)

    # Apply global limit
    all_tasks = all_tasks[: options.limit]

    if not all_tasks:
        print("No tasks found")
        return

    # Print tasks with full identifiers on two lines for easier copying.
    for task in all_tasks:
        attempts = f"{task['attempt']}/{task['max_attempts']}"
        age = format_age(task["updated_at"])
        print(f"task_id={task['task_id']}")
        print(f"  run_id={task['run_id']}")
        print(f"  attempts={attempts}")
        print(f"  age={age}")
        print(f"  queue={task['queue']}")
        print(f"  task_name={task['task_name']}")
        print(f"  status={task['status']}")
        print()

    print()
    print(f"Total: {len(all_tasks)} task(s)")


def cmd_dump_task(args):
    """Dump task or run details including checkpoints."""
    usage = "usage: %prog dump-task [options]"
    parser = build_command_parser(usage)
    parser.add_option(
        "--task-id",
        dest="task_id",
        metavar="UUID",
        help="Task ID to dump",
    )
    parser.add_option(
        "--run-id",
        dest="run_id",
        metavar="UUID",
        help="Run ID to dump",
    )

    examples = [
        "absurdctl dump-task --task-id=019a32d3-8425-7ae2-a5af-2f17a6707666",
        "absurdctl dump-task --run-id=019a32d3-8425-7ae2-a5af-2f17a6707666",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    if not options.task_id and not options.run_id:
        print("Error: Either --task-id or --run-id must be specified", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    if options.task_id and options.run_id:
        print("Error: Cannot specify both --task-id and --run-id", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    config = config_from_options(options)

    # Get list of queues
    queues_result = run_psql(
        config,
        "SELECT queue_name FROM absurd.queues;",
        tuples_only=True,
        no_align=True,
    )

    if not queues_result:
        print("No queues found in the database", file=sys.stderr)
        sys.exit(1)

    queues = [q for q in queues_result.strip().split("\n") if q]

    # Find which queue contains the task/run
    target_queue = None
    task_id = None

    if options.run_id:
        # Search for run_id across all queues
        for queue in queues:
            result = run_psql(
                config,
                f"SELECT task_id FROM absurd.r_{queue} WHERE run_id = '{options.run_id}';",
                tuples_only=True,
                no_align=True,
            )
            if result:
                target_queue = queue
                task_id = result.strip()
                break

        if not target_queue:
            print(f"Run ID '{options.run_id}' not found in any queue", file=sys.stderr)
            sys.exit(1)
    else:
        # Search for task_id across all queues
        task_id = options.task_id
        for queue in queues:
            result = run_psql(
                config,
                f"SELECT COUNT(*) FROM absurd.t_{queue} WHERE task_id = '{task_id}';",
                tuples_only=True,
                no_align=True,
            )
            if result and int(result.strip()) > 0:
                target_queue = queue
                break

        if not target_queue:
            print(f"Task ID '{task_id}' not found in any queue", file=sys.stderr)
            sys.exit(1)

    # Fetch task and runs
    if options.run_id:
        # Fetch specific run
        runs_query = f"""
            SELECT
                t.task_id,
                r.run_id,
                t.task_name,
                t.state,
                r.state as run_state,
                r.attempt,
                t.max_attempts,
                t.params,
                t.retry_strategy,
                t.headers,
                COALESCE(r.failure_reason, r.result) AS final_state,
                r.created_at,
                r.started_at,
                r.completed_at,
                r.failed_at,
                t.cancelled_at,
                COALESCE(r.completed_at, r.failed_at, r.started_at, r.created_at) AS updated_at,
                r.claimed_by
            FROM absurd.t_{target_queue} t
            JOIN absurd.r_{target_queue} r ON r.task_id = t.task_id
            WHERE r.run_id = '{options.run_id}'
        """
    else:
        # Fetch all runs for task
        runs_query = f"""
            SELECT
                t.task_id,
                r.run_id,
                t.task_name,
                t.state,
                r.state as run_state,
                r.attempt,
                t.max_attempts,
                t.params,
                t.retry_strategy,
                t.headers,
                COALESCE(r.failure_reason, r.result) AS final_state,
                r.created_at,
                r.started_at,
                r.completed_at,
                r.failed_at,
                t.cancelled_at,
                COALESCE(r.completed_at, r.failed_at, r.started_at, r.created_at) AS updated_at,
                r.claimed_by
            FROM absurd.t_{target_queue} t
            JOIN absurd.r_{target_queue} r ON r.task_id = t.task_id
            WHERE t.task_id = '{task_id}'
            ORDER BY r.attempt
        """

    runs_rows = run_psql_csv(config, runs_query)

    if not runs_rows:
        print("No data found", file=sys.stderr)
        sys.exit(1)

    # Parse runs
    runs = []
    for parts in runs_rows:
        if len(parts) >= 18:
            runs.append(
                {
                    "task_id": parts[0],
                    "run_id": parts[1],
                    "task_name": parts[2],
                    "task_state": parts[3],
                    "run_state": parts[4],
                    "attempt": parts[5],
                    "max_attempts": parts[6] if parts[6] else None,
                    "params": json.loads(parts[7]) if parts[7] else None,
                    "retry_strategy": json.loads(parts[8]) if parts[8] else None,
                    "headers": json.loads(parts[9]) if parts[9] else None,
                    "final_state": json.loads(parts[10]) if parts[10] else None,
                    "created_at": parts[11],
                    "started_at": parts[12],
                    "completed_at": parts[13],
                    "failed_at": parts[14],
                    "cancelled_at": parts[15],
                    "updated_at": parts[16],
                    "worker_id": parts[17] if parts[17] else None,
                }
            )

    # For each run, fetch checkpoints and waits
    for run in runs:
        # Fetch checkpoints
        checkpoints_query = f"""
            SELECT
                checkpoint_name,
                state,
                status,
                owner_run_id,
                updated_at
            FROM absurd.c_{target_queue}
            WHERE task_id = '{run['task_id']}' AND owner_run_id = '{run['run_id']}'
            ORDER BY updated_at DESC
        """

        checkpoint_rows = run_psql_csv(config, checkpoints_query)

        checkpoints = []
        for parts in checkpoint_rows:
            if len(parts) >= 5:
                checkpoints.append(
                    {
                        "name": parts[0],
                        "state": json.loads(parts[1]) if parts[1] else None,
                        "status": parts[2],
                        "owner_run_id": parts[3],
                        "updated_at": parts[4],
                    }
                )

        run["checkpoints"] = checkpoints

        # Fetch wait states
        waits_query = f"""
            SELECT
                CASE
                    WHEN r.wake_event IS NOT NULL THEN 'event'
                    WHEN r.available_at IS NOT NULL THEN 'sleep'
                    ELSE NULL
                END AS wait_type,
                r.available_at,
                r.wake_event,
                w.step_name,
                r.event_payload,
                e.payload as event_payload_emitted,
                e.emitted_at,
                COALESCE(w.created_at, r.started_at) as updated_at
            FROM absurd.r_{target_queue} r
            LEFT JOIN absurd.w_{target_queue} w ON w.run_id = r.run_id
            LEFT JOIN absurd.e_{target_queue} e ON e.event_name = r.wake_event
            WHERE r.run_id = '{run['run_id']}' AND r.state = 'sleeping'
        """

        waits_rows = run_psql_csv(config, waits_query)

        waits = []
        for parts in waits_rows:
            if len(parts) >= 8 and parts[0]:
                waits.append(
                    {
                        "wait_type": parts[0],
                        "wake_at": parts[1],
                        "wake_event": parts[2] if parts[2] else None,
                        "step_name": parts[3] if parts[3] else None,
                        "payload": json.loads(parts[4]) if parts[4] else None,
                        "event_payload": json.loads(parts[5]) if parts[5] else None,
                        "emitted_at": parts[6] if parts[6] else None,
                        "updated_at": parts[7],
                    }
                )

        run["waits"] = waits

    # Now output the results
    print("=" * 80)
    print(f"TASK DUMP")
    print("=" * 80)
    print()

    for idx, run in enumerate(runs):
        if idx > 0:
            print()
            print("-" * 80)
            print()

        print(f"BASIC INFORMATION")
        print(f"  Current status:    {run['run_state']}")
        print(f"  Task Name:         {run['task_name']}")
        print(f"  Queue:             {target_queue}")
        print(f"  Task ID:           {run['task_id']}")
        print(f"  Run ID:            {run['run_id']}")
        if run["worker_id"]:
            print(f"  Worker ID:         {run['worker_id']}")
        print()

        print(f"TIMING")
        print(f"  Created:           {format_timestamp(run['created_at'])}")
        print(f"  Updated:           {format_timestamp(run['updated_at'])}")
        if run["started_at"]:
            print(f"  Started:           {format_timestamp(run['started_at'])}")
        if run["completed_at"]:
            print(f"  Completed:         {format_timestamp(run['completed_at'])}")
        if run["failed_at"]:
            print(f"  Failed:            {format_timestamp(run['failed_at'])}")
        if run["cancelled_at"]:
            print(f"  Cancelled:         {format_timestamp(run['cancelled_at'])}")
        print()

        # Wait states
        if run["waits"]:
            print(f"WAIT STATES")
            for wait in run["waits"]:
                wait_type = (
                    wait["wait_type"].capitalize() + " wait"
                    if wait["wait_type"]
                    else "Wait"
                )
                print(f"  {wait_type}")
                if wait["step_name"]:
                    print(f"    Step:            {wait['step_name']}")
                if wait["wake_at"]:
                    print(f"    Wake at:         {format_timestamp(wait['wake_at'])}")
                if wait["wake_event"]:
                    print(f"    Wake event:      {wait['wake_event']}")
                if wait["emitted_at"]:
                    print(
                        f"    Last emit:       {format_timestamp(wait['emitted_at'])}"
                    )
                print(f"    Updated:         {format_timestamp(wait['updated_at'])}")
                if wait["payload"]:
                    print(f"    Wait payload:")
                    for line in format_json_value(wait["payload"]).split("\n"):
                        print(f"      {line}")
                if wait["event_payload"]:
                    print(f"    Event payload:")
                    for line in format_json_value(wait["event_payload"]).split("\n"):
                        print(f"      {line}")
            print()

        print(f"RETRY INFORMATION")
        max_attempts_str = run["max_attempts"] if run["max_attempts"] else "unlimited"
        print(f"  Attempt:           {run['attempt']} of {max_attempts_str}")
        if run["retry_strategy"]:
            print(f"  Retry Strategy:")
            for line in format_json_value(run["retry_strategy"]).split("\n"):
                print(f"    {line}")
        print()

        # Parameters
        if run["params"]:
            print(f"PARAMETERS")
            for line in format_json_value(run["params"]).split("\n"):
                print(f"  {line}")
            print()

        # Headers
        if run["headers"]:
            print(f"HEADERS")
            for line in format_json_value(run["headers"]).split("\n"):
                print(f"  {line}")
            print()

        # Final state
        if run["final_state"]:
            state_label = "FAILURE" if run["run_state"] == "failed" else "FINAL STATE"
            print(state_label)
            for line in format_json_value(run["final_state"]).split("\n"):
                print(f"  {line}")
            print()

        # Checkpoints
        if run["checkpoints"]:
            print(f"CHECKPOINTS")
            for checkpoint in run["checkpoints"]:
                print(f"  {checkpoint['name']} ({checkpoint['status']})")
                print(
                    f"    Updated:         {format_timestamp(checkpoint['updated_at'])}"
                )
                if checkpoint["state"]:
                    print(f"    State:")
                    for line in format_json_value(checkpoint["state"]).split("\n"):
                        print(f"      {line}")
                print()


def cmd_agent_help(args):
    """Print quick guidance for automated agents."""
    if args:
        print("Error: agent-help does not accept arguments", file=sys.stderr)
        sys.exit(1)

    message = textwrap.dedent(
        """
        This project uses "Absurd", a durable workflow system built on postgres.  It can be
        debugged with the `absurdctl` command-line tool.

        Connection: set PGHOST, PGPORT, PGUSER, PGDATABASE, and PGPASSWORD just like for psql.

        Core commands to explore:
        - list-queues: discover available queues (`absurdctl list-queues`)
        - list-tasks: inspect recent activity in a queue (`absurdctl list-tasks --queue=default`)
        - dump-task: pull full details for a task or run (`absurdctl dump-task --task-id=<uuid>`)
        - spawn-task: enqueue new work (`absurdctl spawn-task my-task`)

        Use `absurdctl <command> --help` to see every option when you need more detail.

        Task state includes all checkpointed step results as JSON.
        """
    ).strip()

    print(message)


def show_help():
    print(
        """Usage: absurdctl COMMAND [OPTIONS]

A command-line utility for managing Absurd queues.

Commands:
  init            Initialize the Absurd schema by applying absurd.sql
  cleanup         Clean up old completed, failed, or cancelled tasks and events
  create-queue    Create a new queue
  drop-queue      Drop an existing queue
  list-queues     List all existing queues
  spawn-task      Spawn a new task
  list-tasks      List tasks with optional filtering
  dump-task       Dump task or run details including checkpoints
  agent-help      Print quick guidance tailored for coding agents
  help            Show this help message

Run 'absurdctl COMMAND --help' for more information on a command.

Environment Variables:
  PGHOST          Database host
  PGPORT          Database port
  PGUSER          Database user
  PGDATABASE      Database name
  PGPASSWORD      Database password (recommended over command line)

Examples:
  absurdctl init
  absurdctl cleanup myqueue 30
  absurdctl create-queue myqueue
  absurdctl drop-queue myqueue --yes
  absurdctl list-queues
  absurdctl spawn-task my-task -P foo=bar -P count:=42
  absurdctl list-tasks --queue=default --status=failed
  absurdctl dump-task --task-id=019a32d3-8425-7ae2-a5af-2f17a6707666
  absurdctl agent-help >> AGENTS.md
"""
    )


def main():
    if len(sys.argv) < 2 or sys.argv[1] in ("help", "--help", "-h"):
        show_help()
        sys.exit(0)

    command = sys.argv[1]
    args = sys.argv[2:]

    if command == "cleanup":
        cmd_cleanup(args)
    elif command == "create-queue":
        cmd_create_queue(args)
    elif command == "drop-queue":
        cmd_drop_queue(args)
    elif command == "list-queues":
        cmd_list_queues(args)
    elif command == "init":
        cmd_init(args)
    elif command == "spawn-task":
        cmd_spawn_task(args)
    elif command == "list-tasks":
        cmd_list_tasks(args)
    elif command == "dump-task":
        cmd_dump_task(args)
    elif command == "agent-help":
        cmd_agent_help(args)
    else:
        print(f"Unknown command: {command}", file=sys.stderr)
        print("")
        show_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
